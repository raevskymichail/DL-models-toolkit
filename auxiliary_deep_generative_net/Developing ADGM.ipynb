{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = mnist.train._images.reshape(55000, 28, 28, 1)\n",
    "Y = mnist.train._labels\n",
    "index = np.arange(55000)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "th = 50000\n",
    "\n",
    "X_labeled = util.BatchFeeder(X[index[:th]], Y[index[:th]], 128)\n",
    "X_unlabeled = util.BatchFeeder(X[index[th:]], Y[index[th:]], 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADGM:\n",
    "    def __init__(self):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        #Building the model\n",
    "        self.built = False\n",
    "        self.sesh = tf.Session()\n",
    "        self.e = 0\n",
    "        \n",
    "        # Tracking data\n",
    "        self.learning_curve = []\n",
    "        \n",
    "        # Parameters\n",
    "        self.num_classes = 10\n",
    "        self.batch_size = 128\n",
    "        self.latent_size = 128\n",
    "        self.hidden_size = 256\n",
    "        self.supervised_scaling_const = 0.1 * (55000 / 100)\n",
    "        self.learning_rate = 0.001\n",
    "        self.outputs = {}\n",
    "        self._losses = {}\n",
    "        \n",
    "        # Building the graph\n",
    "        self.ops = self.build()\n",
    "        self.sesh.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def build(self):\n",
    "        # Placeholders for input and dropout probs.\n",
    "        if self.built:\n",
    "            return -1\n",
    "        else:\n",
    "            self.built = True\n",
    "            \n",
    "        # Input Data X\n",
    "        self.x_labeled = tf.placeholder(tf.float32, shape=[self.batch_size, 28, 28, 1])\n",
    "        self.x_unlabeled = tf.placeholder(tf.float32, shape=[self.batch_size, 28, 28, 1])\n",
    "        self.x = tf.concat([self.x_labeled, self.x_unlabeled], 0)\n",
    "        self.x_unlabeled_tiled = tf.tile(self.x_unlabeled, [self.num_classes, 1, 1, 1])\n",
    "        \n",
    "        # Input Data Y\n",
    "        self.y_labeled = tf.placeholder(tf.float32, shape=[self.batch_size, self.num_classes])\n",
    "        self.y, self.y_unlabeled = self.generate_y(self.y_labeled)\n",
    "        \n",
    "        self.outputs = {'labeled': {'x_in': self.x_labeled}, 'unlabeled': {'x_in': self.x_unlabeled_tiled}}\n",
    "        \n",
    "        # Building the Q networks\n",
    "        q_x = self.encoder(self.x)\n",
    "        q_a_x = self.gaussian_stochastic(q_x, self.latent_size, 'q_a')\n",
    "        q_y_ax_input = self.linear_deterministic([(q_a_x, 'q_a_inter_1'), (q_x, 'q_x_inter_1')])\n",
    "        _ = self.multinomial_stochastic(q_y_ax_input, self.num_classes, 'q_y')\n",
    "        q_z_axy_input = self.linear_deterministic([(q_a_x, 'q_a_inter'), (q_x, 'q_x_inter'), (self.y, 'y_inter')])\n",
    "        q_z_axy = self.gaussian_stochastic(q_z_axy_input, self.latent_size, 'q_z')\n",
    "        \n",
    "        # Building the P networks\n",
    "        p_a_yz_input = self.linear_deterministic([(self.y, 'y_inter_2'), (q_z_axy, 'q_z_axy_inter')])\n",
    "        p_a_yz = self.gaussian_stochastic(p_a_yz_input, self.latent_size, 'p_a')\n",
    "        p_x_input = self.linear_deterministic([(p_a_yz, 'p_a_yz'), (q_z_axy, 'q_z_axy'), (self.y, 'q_y_ax')])\n",
    "        p_x = self.decoder(p_x_input)\n",
    "        x_hat = self.gaussian_stochastic(p_x, 1, 'p_x')\n",
    "        \n",
    "        # Get the elbo term to minimize\n",
    "        elbo = self.add_losses()\n",
    "                \n",
    "        # Defining optimization procedure.\n",
    "        with tf.name_scope(\"Adam_optimizer\"):\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads_and_vars = optimizer.compute_gradients(elbo, tvars)\n",
    "            clipped = [(tf.clip_by_value(grad, -5, 5), tvar) for grad, tvar in grads_and_vars]\n",
    "            train = optimizer.apply_gradients(clipped, name=\"minimize_cost\")\n",
    "        \n",
    "        return dict(\n",
    "            train=train,\n",
    "            elbo=elbo,\n",
    "            xl=self.x_labeled,\n",
    "            xul=self.x_unlabeled,\n",
    "            yl=self.y_labeled,\n",
    "            xhat = x_hat\n",
    "        )\n",
    "        \n",
    "        \n",
    "    # encoder network\n",
    "    def encoder(self, _input):\n",
    "        with tf.variable_scope('encoder'):\n",
    "            fn = tf.nn.elu\n",
    "            filtersize = (5,5)\n",
    "            \n",
    "            # layer 1\n",
    "            n_filt = 64 \n",
    "            layer1 = tf.layers.conv2d(_input, n_filt, filtersize, strides=(2,2), padding=\"same\", activation=None)\n",
    "            #layer1 = tf.contrib.layers.batch_norm(layer1, is_training=bn)\n",
    "            layer1 = fn(layer1)\n",
    "            \n",
    "            # layer 2\n",
    "            n_filt = 128 \n",
    "            layer2 = tf.layers.conv2d(layer1, n_filt, filtersize, strides=(2,2), padding=\"same\", activation=None)\n",
    "            #layer2 = tf.contrib.layers.batch_norm(layer2, is_training=bn)\n",
    "            layer2 = fn(layer2)\n",
    "            \n",
    "            # layer 3\n",
    "            n_filt = 256 \n",
    "            layer3 = tf.layers.conv2d(layer2, n_filt, filtersize, strides=(2,2), padding=\"same\", activation=None)\n",
    "            #layer3 = tf.contrib.layers.batch_norm(layer3, is_training=bn)\n",
    "            layer3 = fn(layer3)\n",
    "            \n",
    "            # getting the features\n",
    "            x_features_all = tf.reduce_mean(layer3, axis=[1, 2]) #Global average pooling happens here.\n",
    "            x_features_labeled, x_features_unlabeled = tf.split(x_features_all, 2)\n",
    "\n",
    "        x_features_tiled = tf.tile(x_features_unlabeled, [self.num_classes, 1])\n",
    "        x_features = tf.concat([x_features_labeled, x_features_tiled], 0)\n",
    "        return x_features\n",
    "    \n",
    "    # decoder network\n",
    "    def decoder(self, p_x):\n",
    "        with tf.variable_scope('decoder'):\n",
    "            fn = tf.nn.relu\n",
    "            filtersize = (5,5)\n",
    "            \n",
    "            # Maping from latenet to some dimension with fully connected layer.\n",
    "            _input = tf.reshape(p_x, (self.batch_size*(self.num_classes+1), self.latent_size))\n",
    "            net = tf.contrib.slim.fully_connected(_input, 1024, activation_fn=None)\n",
    "            #net = tf.contrib.layers.batch_norm(net, is_training=bn)\n",
    "            net = tf.nn.relu(net)\n",
    "            net = tf.contrib.slim.fully_connected(net, 7*7*128) \n",
    "            #net = tf.contrib.layers.batch_norm(net, is_training=bn)\n",
    "            \n",
    "            net = tf.reshape(net, [-1, 7, 7, 128])\n",
    "            \n",
    "            # layer 1 (outputs: 512x4x4x4)\n",
    "            n_filt = 64 \n",
    "            layer1 = tf.layers.conv2d_transpose(net, n_filt, filtersize, strides=(2,2), padding=\"same\", activation=None)\n",
    "            #layer1 = tf.contrib.layers.batch_norm(layer1, is_training=bn)\n",
    "            layer1 = fn(layer1)\n",
    "            \n",
    "            # layer 2 (outputs: 256x8x8x8)\n",
    "            n_filt = 1 \n",
    "            layer2 = tf.layers.conv2d_transpose(layer1, n_filt, filtersize, strides=(2,2), padding=\"same\", activation=None)\n",
    "            #layer2 = tf.contrib.layers.batch_norm(layer2, is_training=bn)\n",
    "            layer2 = fn(layer2)\n",
    "        return layer2\n",
    "    \n",
    "    # test\n",
    "    def gaussian_stochastic(self, input_tensor, num_maps, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            input_tensor = tf.expand_dims(tf.expand_dims(input_tensor, 1), 1) if len(input_tensor.get_shape()) != 4 \\\n",
    "                else input_tensor\n",
    "                \n",
    "            # For some reasons there is additional layer here.\n",
    "            # Conv layer is used to model dense layer for speed up\n",
    "            intermediate = tf.contrib.slim.conv2d(input_tensor, self.hidden_size, [1, 1], scope='conv1')\n",
    "            \n",
    "            # MEAN of Gaussian\n",
    "            mean = tf.contrib.slim.conv2d(intermediate,\n",
    "                                          num_maps, \n",
    "                                          [1, 1], \n",
    "                                          activation_fn=None, \n",
    "                                          scope='mean')\n",
    "            # SIGMA**2 for Gaussian range (0 --> inf)\n",
    "            sigma2 = tf.nn.softplus(\n",
    "                                tf.contrib.slim.conv2d(intermediate,\n",
    "                                num_maps,\n",
    "                                [1, 1],\n",
    "                                activation_fn=None,\n",
    "                                scope='sigma2'))\n",
    "            # DRAW samples\n",
    "            rv_single_draw = mean + tf.sqrt(sigma2) * tf.random_normal(tf.shape(mean))\n",
    "\n",
    "        # Record outputs with appropriate keys.\n",
    "        self.split_labeled_unlabeled(mean, '{}_mu'.format(scope))\n",
    "        self.split_labeled_unlabeled(sigma2, '{}_sigma2'.format(scope))\n",
    "        self.split_labeled_unlabeled(rv_single_draw, '{}_sample'.format(scope))\n",
    "        return rv_single_draw\n",
    "    \n",
    "    # Stochastic output for multinomial distribution\n",
    "    def multinomial_stochastic(self, input_tensor, num_maps, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            input_tensor = tf.expand_dims(tf.expand_dims(input_tensor, 1), 1) if len(input_tensor.get_shape()) != 4 \\\n",
    "                else input_tensor\n",
    "                \n",
    "            # For some reasons there is additional layer here.\n",
    "            # Conv layer is used to model dense layer for speed up\n",
    "            intermediate = tf.contrib.slim.conv2d(input_tensor, \n",
    "                                       self.hidden_size, \n",
    "                                       [1, 1], \n",
    "                                       scope='conv1')\n",
    "            # I need to figure out what Pi is.\n",
    "            pi = tf.contrib.slim.conv2d(intermediate,\n",
    "                                        num_maps, \n",
    "                                        [1, 1], \n",
    "                                        activation_fn=None, \n",
    "                                        scope='mean')\n",
    "            \n",
    "            rv_single_draw = tf.nn.softmax(pi)\n",
    "            \n",
    "        self.split_labeled_unlabeled(pi, '{}_pi'.format(scope))\n",
    "        self.split_labeled_unlabeled(rv_single_draw, '{}_sample'.format(scope))\n",
    "        return rv_single_draw\n",
    "\n",
    "    # linear deterministic\n",
    "    def linear_deterministic(self, inputs_list_with_scopes):\n",
    "        with tf.variable_scope('linear'):\n",
    "            outputs_list = list()\n",
    "            for tensor, scope in inputs_list_with_scopes:\n",
    "                tensor = tf.expand_dims(tf.expand_dims(tensor, 1), 1) if len(tensor.get_shape()) != 4 else tensor\n",
    "                linear_layer = tf.contrib.slim.conv2d(tensor, self.latent_size, [1, 1], scope=scope)\n",
    "                outputs_list.append(linear_layer)\n",
    "            return sum(outputs_list)\n",
    "        \n",
    "    # Calculate elbo for both labeled and unlabeled data.\n",
    "    def add_losses(self):\n",
    "        # Losses\n",
    "        lb_l = self._calc_lb('labeled')\n",
    "        self._losses['lb_l'] = tf.reduce_mean(lb_l)\n",
    "        lb_u = self._calc_lb('unlabeled')\n",
    "        self._losses['lb_u'] = tf.reduce_mean(lb_u)\n",
    "        elbo = tf.reduce_mean(lb_l) + tf.reduce_mean(lb_u)\n",
    "        self._losses['lb'] = elbo\n",
    "        return elbo\n",
    "    \n",
    "    # Calculates Elbo for labeled and unlabeled data.\n",
    "    def _calc_lb(self, data_type):\n",
    "\n",
    "        # Go over these with the paper.\n",
    "        outputs = self.outputs[data_type]\n",
    "        log_qa = self.gaussian_log_density(outputs['q_a_sample'], outputs['q_a_mu'], outputs['q_a_sigma2'])\n",
    "        log_qz = self.gaussian_log_density(outputs['q_z_sample'], outputs['q_z_mu'], outputs['q_z_sigma2'])\n",
    "        log_pz = self.standard_gaussian_log_density(outputs['q_z_sample'])\n",
    "        log_pa = self.gaussian_log_density(outputs['q_a_sample'], outputs['p_a_mu'], outputs['p_a_sigma2'])\n",
    "        # We are assuming gaussian output here.\n",
    "        log_px = self.gaussian_log_density(outputs['x_in'], outputs['p_x_mu'], outputs['p_x_sigma2'])\n",
    "\n",
    "        self._losses['{}_log_qa'.format(data_type)] = tf.reduce_mean(log_qa)\n",
    "        self._losses['{}_log_qz'.format(data_type)] = tf.reduce_mean(log_qz)\n",
    "        self._losses['{}_log_pz'.format(data_type)] = tf.reduce_mean(log_pz)\n",
    "        self._losses['{}_log_pa'.format(data_type)] = tf.reduce_mean(log_pa)\n",
    "        self._losses['{}_log_px'.format(data_type)] = tf.reduce_mean(log_px)\n",
    "        \n",
    "        if data_type == 'labeled':\n",
    "            temp = tf.expand_dims(tf.expand_dims(self.y_labeled, axis=1),axis=1)\n",
    "            log_py = self.standard_multinomial_log_density(temp, self.num_classes)\n",
    "            lb_sum = tf.squeeze(log_py) + log_pz + log_pa + log_px - log_qa - log_qz\n",
    "            \n",
    "            log_qy = self.multinomial_log_density(outputs['q_y_sample'], self.y_labeled)\n",
    "            lb = lb_sum - self.supervised_scaling_const * log_qy\n",
    "            tf.summary.scalar('labeled_log_qy', tf.reduce_sum(log_qy))\n",
    "            \n",
    "        else:  \n",
    "            temp = tf.expand_dims(tf.expand_dims(self.y_unlabeled, axis=1),axis=1)\n",
    "            log_py = self.standard_multinomial_log_density(temp, self.num_classes)\n",
    "            lb_sum = tf.squeeze(log_py) + log_pz + log_pa + log_px - log_qa - log_qz\n",
    "            \n",
    "            lb_sum = tf.transpose(tf.reshape(lb_sum, [self.num_classes, self.batch_size]))\n",
    "            qy = tf.slice(tf.squeeze(outputs['q_y_sample']), [0, 0], [self.batch_size, 10])\n",
    "            qy += 1e-8\n",
    "            qy /= tf.reduce_sum(qy, axis=1, keep_dims=True)\n",
    "            lb = tf.reduce_sum(qy * (tf.reshape(lb_sum, tf.shape(qy)) - tf.log(qy)), axis=1)\n",
    "            \n",
    "        tf.summary.scalar('{}_log_qa'.format(data_type), tf.reduce_sum(log_qa))\n",
    "        tf.summary.scalar('{}_log_qz'.format(data_type), tf.reduce_sum(log_qz))\n",
    "        tf.summary.scalar('{}_log_pz'.format(data_type), tf.reduce_sum(log_pz))\n",
    "        tf.summary.scalar('{}_log_pa'.format(data_type), tf.reduce_sum(log_pa))\n",
    "        tf.summary.scalar('{}_log_py'.format(data_type), tf.reduce_sum(log_py))\n",
    "        tf.summary.scalar('{}_log_px'.format(data_type), tf.reduce_sum(log_px))\n",
    "\n",
    "        return lb\n",
    "        \n",
    "    # Creates a tensor of size batchsize*numclasses by numclasses.\n",
    "    # All possible labelings to marginalize over for unlabeled data.\n",
    "    def generate_y(self, y_labeled):\n",
    "        y_unlabeled_tiled = tf.reshape(tf.tile(tf.eye(self.num_classes), [1, self.batch_size]),\n",
    "                                       [self.num_classes * self.batch_size, self.num_classes])\n",
    "        y_all = tf.concat([y_labeled, y_unlabeled_tiled], 0)\n",
    "        return y_all, y_unlabeled_tiled\n",
    "    \n",
    "    # Split\n",
    "    def split_labeled_unlabeled(self, tensor, key):\n",
    "        if tensor.get_shape()[0] % (self.num_classes + 1) == 0:\n",
    "            _all = tf.split(tensor, self.num_classes + 1)\n",
    "            self.outputs['labeled'][key] = _all[0]\n",
    "            self.outputs['unlabeled'][key] = tf.concat(_all[1:], 0)\n",
    "        else:\n",
    "            self.outputs['labeled'][key], self.outputs['unlabeled'][key] = tf.split(tensor, 2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def standard_gaussian_log_density(x):\n",
    "        c = - 0.5 * math.log(2 * math.pi)\n",
    "        density = c - tf.square(x) / 2\n",
    "        return -tf.reduce_mean(tf.reduce_sum(density, axis=-1), axis=[1, 2])\n",
    "    \n",
    "    @staticmethod\n",
    "    def standard_multinomial_log_density(x, num_classes):\n",
    "        total = tf.stack([tf.shape(x)[0] * tf.shape(x)[3]])\n",
    "        labels = tf.reshape(tf.tile(tf.constant([1 / num_classes]), total), tf.shape(x))\n",
    "        density = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=x)\n",
    "        return tf.reduce_sum(density, axis=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_log_density(x, mu, sigma2):\n",
    "        c = - 0.5 * math.log(2 * math.pi)\n",
    "        density = c - tf.log(sigma2) / 2 - tf.squared_difference(x, mu) / (2 * sigma2)\n",
    "        return -tf.reduce_mean(tf.reduce_sum(density, axis=-1), axis=(1, 2))\n",
    "\n",
    "    @staticmethod\n",
    "    def multinomial_log_density(x, mu):\n",
    "        density = tf.nn.softmax_cross_entropy_with_logits(labels=mu, logits=x)\n",
    "        return tf.reduce_sum(density, axis=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def define_initializer():\n",
    "        initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n",
    "        return initializer\n",
    "    \n",
    "    # training procedure.\n",
    "    def train(self, X_labeled, X_unlabeled, epochs, valid=None):\n",
    "        # Making the saver object.\n",
    "        e = 0\n",
    "        log = []\n",
    "        xhats = []\n",
    "        while e < epochs:\n",
    "            #Training happens here.\n",
    "            xl, yl = X_labeled.next()\n",
    "            xul, _ = X_unlabeled.next()\n",
    "            \n",
    "            feed_dict = {self.ops[\"xl\"]: xl,\n",
    "                         self.ops[\"xul\"]: xul,\n",
    "                         self.ops[\"yl\"]: yl}\n",
    "            ops_to_run = [self.ops[\"elbo\"],\n",
    "                          self.ops[\"train\"],\n",
    "                          self.ops[\"xhat\"]\n",
    "                         ]\n",
    "            elbo, _, xhat = self.sesh.run(ops_to_run, feed_dict)\n",
    "            log.append(elbo)\n",
    "            xhats.append(xhat)\n",
    "            self.e+=1\n",
    "            e+= 1\n",
    "        return log, xhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = ADGM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m.train(X_labeled, X_unlabeled, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9303f1e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92e598ddd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(output[1][-1][0][:, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
