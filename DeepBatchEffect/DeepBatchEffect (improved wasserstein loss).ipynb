{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = mnist.train._images.reshape(55000, 28, 28, 1)\n",
    "Y = mnist.train._labels\n",
    "index = np.arange(55000)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "#batch1 = util.BatchFeeder(X[index[:27000]], Y[index[:27000]], 64)\n",
    "#batch2 = util.BatchFeeder(X[index[27000:54000]]+np.ones((27000,28,28,1))/2.0, Y[index[27000:54000]], 64)\n",
    "\n",
    "batch1 = util.BatchFeeder(X[index[:128*210]], np.zeros((128*210, 1)), 128)\n",
    "batch2 = util.BatchFeeder(X[index[128*210:128*210*2]]+np.ones((128*210,28,28,1))/2.0, np.ones((128*210, 1)), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d2f325650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = batch1.next()[0][0,:,:,0]\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(x, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAABUtJREFUeJztnU1oXFUYhp/XUUuDkhr8oWiqQUJI\nViMEI9idEcRNdBExC1tKoF1YMOCmSKF250JdpdjWWuhCaiwK7aIQJLjJoqZJKZq2qEXsJJpWUyhG\n00YaPxczU5LOpHPn75u5k/NAmLnn/r288843c+aeeyIzI+DDfbUWsJ4IZjsSzHYkmO1IMNuRYLYj\nwWxHyjJb0iuSfpR0WdKeSolqVFRqp0ZSAvgJeBmYBc4CA2Z2sXLyGov7y9j3eeCymf0CIOkLoA9Y\n0+ympibbtGlTGaesT27cuMHi4qIKbVeO2U8CMyuWZ4GeuzeStBPYCdDc3MyuXbvKOGV9cujQoUjb\nlVOz872SOTXJzA6bWbeZdTc1NZVxuvhTjtmzQOuK5aeA38uT09iUY/ZZoF1Sm6QHgTeBU5WR1ZiU\nXLPN7Lak3cAokACOmtmFiilrQMr5gMTMTgOnK6Sl4Qk9SEeC2Y4Esx0JZjsSzHakrG8j9UJ/fz8A\nXV1dOetOnDgBwMWLtf99LCTbkVgmO5FIALB3796C22ZTf/z4cQDm5uYAWFhYqJK6tQnJdiSWyd62\nbVve9lu3bgFw8OBBhoaGVq0bGBhYtbx///7qiLsHIdmOxCrZzc3NAGzZsmVV+/z8PAAHDhxw11QM\nIdmOxCrZbW1teduPHDmS0zY+Pg7A1q1bq6qpGEKyHYlVsvP1EAGWlpZy2uop0VlCsh2JVbLb29tX\nLU9OThZ9jNHR0UrJKZqQbEdiley7mZ2dLXqfM2fOVEFJNGKV7FQqRSqVurPc0dFBR0fHneVEIkEi\nkWBwcLAW8goSK7PjTqzKyNjYGAA7duwAoLOzE4B9+/bVTFMxhGQ7EqtkZ+t19hLXWp2ceiUk25FY\nJTtL9iJudghyS0sLAMvLy0D60lc91vGQbEdimewsi4uLqx7rnYLJltQq6VtJlyRdkPROpr1F0jeS\nfs48PlJ9ufEmShm5DbxrZp3AC8DbkrqAPcCYmbUDY5nlumFmZoaZmZnCGzpS0GwzmzOzc5nnC8Al\n0jcv9QHHMpsdA16rlshGoaiaLekZ4DngO+AJM5uD9Asi6fGKqyuD6elpAFpbW1e19/X1AXDy5El3\nTZG/jUh6CPgKGDKzv4rYb6ekSUmTcfkgqxaRzJb0AGmjPzezrzPN1yRtzqzfDPyRb99a3Zo3MTHB\nxMRETnsymSSZTLrpWEmUbyMCPgMumdnHK1adArZnnm8H/N+XMSNKzX4ReAv4QdL5TNt7wAfAl5IG\ngRTQXx2J1WHDhg1A/ovF1aKg2WY2Tv67eQFeqqycxqbhu+vDw8MMDw/ntPf29tLb2+uqpeHNridi\n/dtIFK5fvw7AzZs3Adi4cSMA3d3dAFy9ehWAqampqmsJyXZk3Zg9MjLCyMhITntPTw89PTnTpFSF\ndWN2PdDwNTvLlStXgNrc3pElJNuRYLYjwWxHSp7Xr6STSX8C/wDzbietPI+Sq/9pM3us0I6uZgNI\nmjSzbteTVpBy9Icy4kgw25FamH24BuesJCXrd6/Z65lQRhxxMzuOc23fYzTY+5J+k3Q+8/dqpON5\nlJG4zrWdGTWw2czOSXoYmCI9GOkN4G8z+7CY43kl+85c22b2L5Cda7uuucdosJLwMjvfXNsli64F\nd40GA9gt6XtJR6MOKvUyO9Jc2/VKntFgnwDPAklgDvgoynG8zI7tXNv5RoOZ2TUzWzaz/4BPSZfJ\ngniZHcu5ttcaDZYddpfhdWA6yvFcrtTEeK7ttUaDDUhKki6FvwKR/pFD6EE6EnqQjgSzHQlmOxLM\ndiSY7Ugw25FgtiPBbEf+B/lSnzX5fK63AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d127547d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = batch2.next()[0][0,:,:,0]\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(x, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with 2 layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepBatch:\n",
    "    def __init__(self):\n",
    "        # Reset all existing tensors\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Parameters\n",
    "        self.built = False\n",
    "        self.batchsize = 128\n",
    "        self._lambda = 10\n",
    "        self.sesh = tf.Session()\n",
    "        self.e = 0\n",
    "        \n",
    "        # Building the graph\n",
    "        self.ops = self.build()\n",
    "        self.sesh.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def build(self):\n",
    "        if self.built:\n",
    "            return -1\n",
    "        else:\n",
    "            self.built = True\n",
    "             \n",
    "        # Placeholders for input\n",
    "        x1 = tf.placeholder(tf.float32, shape=[self.batchsize, 28, 28, 1], name=\"x1\")\n",
    "        x2 = tf.placeholder(tf.float32, shape=[self.batchsize, 28, 28, 1], name=\"x2\")\n",
    "        \n",
    "        # Network\n",
    "        out1 = self.discriminator(x1, reuse=None)\n",
    "        out2 = self.discriminator(x2, reuse=True)\n",
    "            \n",
    "        # Define cost as the sum of KL and reconstrunction ross with BinaryXent.\n",
    "        with tf.name_scope(\"cost\"):\n",
    "            \n",
    "            ########### Loss calculations ############\n",
    "            alpha = tf.random_uniform(shape=[self.batchsize,1] ,minval =0., maxval=1.) # here we calculate the gradient penalty \n",
    "            difference = x2 - x1\n",
    "            inter = []\n",
    "            for i in range(self.batchsize): \n",
    "                inter.append(difference[i] *alpha[i])\n",
    "            inter = tf.stack(inter)\n",
    "            \n",
    "            interpolates = x1 + inter\n",
    "            gradients = tf.gradients(self.discriminator(interpolates, reuse= True),[interpolates])[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes-1.)**2.)\n",
    "        \n",
    "            d_loss = -tf.reduce_mean(out1) + tf.reduce_mean(out2) + 10.*gradient_penalty\n",
    "            g_loss = -tf.reduce_mean(out2)\n",
    "    \n",
    "        # Optimization\n",
    "        with tf.name_scope(\"Adam_optimizer\"):\n",
    "            train = tf.train.AdamOptimizer( learning_rate = 1e-4, beta1=0.5, beta2=0.9).minimize(d_loss)\n",
    "            gs = tf.gradients(ys=g_loss, xs=x2)[0]\n",
    "            print gs\n",
    "            \n",
    "        return dict(\n",
    "            x1 = x1,  \n",
    "            x2 = x2,  \n",
    "            train = train,\n",
    "            d_loss = d_loss,\n",
    "            g_loss = g_loss,\n",
    "            gs = gs\n",
    "        )\n",
    "    \n",
    "    def discriminator(self, _input, reuse=None):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "            # Network\n",
    "            layer1 = tf.contrib.layers.conv2d(_input, 64, kernel_size=(5,5), activation_fn=tf.nn.relu)\n",
    "            layer1 = tf.contrib.layers.max_pool2d(layer1, kernel_size=(3,3), stride=(2,2))\n",
    "\n",
    "            layer2 = tf.contrib.layers.conv2d(layer1, 128, kernel_size=(5,5), activation_fn=tf.nn.relu)\n",
    "            layer2 = tf.contrib.layers.max_pool2d(layer2, kernel_size=(3,3), stride=(2,2))\n",
    "\n",
    "            dense = tf.contrib.layers.flatten(layer2)\n",
    "            out = tf.contrib.layers.fully_connected(dense, 1, activation_fn=tf.identity)\n",
    "        return out\n",
    "    \n",
    "    # Closing session\n",
    "    def close(self):\n",
    "        self.sesh.close()\n",
    "    \n",
    "    # training procedure.\n",
    "    def train(self, X1, X2, epochs):\n",
    "        \n",
    "        # Defining the number of batches per epoch\n",
    "        batch_num = int(np.ceil(X1.n*1.0/X1.batch_size))\n",
    "        \n",
    "        e = 0\n",
    "        start_e = self.e\n",
    "        ret = []\n",
    "        while e < epochs:\n",
    "            \n",
    "            if e%5 == 0:\n",
    "                temp = []\n",
    "            \n",
    "            for i in range(batch_num):\n",
    "                #Training happens here.\n",
    "                batch1 = X1.next()\n",
    "                batch2 = X2.next()\n",
    "                feed_dict = {self.ops[\"x1\"]: batch1[0],\n",
    "                             self.ops[\"x2\"]: batch2[0]}\n",
    "                ops_to_run = [self.ops[\"d_loss\"],\n",
    "                              self.ops[\"g_loss\"],\n",
    "                              self.ops[\"gs\"],\n",
    "                              self.ops[\"train\"]]\n",
    "                cost, _, gs, _= self.sesh.run(ops_to_run, feed_dict)\n",
    "                \n",
    "                sys.stdout.write(\"\\rEpoch: [%2d/%2d] Batch: [%2d/%2d] loss: %.2f\"%(self.e, start_e+epochs, i, batch_num, -1*cost))\n",
    "\n",
    "                if e%5 == 0:\n",
    "                    temp.append(batch2[0]-0.01*gs)\n",
    "                \n",
    "            if e%5 == 0:\n",
    "                ret.append(X)\n",
    "                temp = np.concatenate(temp, axis=0)\n",
    "                X2 = util.BatchFeeder(temp, np.ones((128*210, 1)), 128)\n",
    "            self.e+=1\n",
    "            e+= 1\n",
    "        return gs, np.concatenate([batch1[0], batch2[0]], axis=0), ret\n",
    "            \n",
    "    def save(self, folder):\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        os.system(\"mkdir \"+folder)\n",
    "        saver.save(self.sesh, folder+\"/model.ckpt\")\n",
    "        \n",
    "    def load(self, folder):\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        saver.restore(self.sesh, folder+\"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Adam_optimizer/gradients_1/discriminator_1/Conv/Conv2D_grad/Conv2DBackpropInput:0\", shape=(128, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = DeepBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/20] Batch: [209/210] loss: 209.56"
     ]
    }
   ],
   "source": [
    "out = model.train(batch1, batch2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind: 110\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAABTCAYAAAAlW238AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+H8KLDXQzGgSfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d2fc4b9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(128)\n",
    "print \"ind:\", index\n",
    "\n",
    "plt.figure(figsize=(3,1))\n",
    "plt.subplot(131)\n",
    "plt.imshow(out[1][index, :, :, 0], cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.yticks([],[])\n",
    "plt.xticks([],[])\n",
    "plt.title(\"original\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(out[1][index+128, :, :, 0], cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.yticks([],[])\n",
    "plt.xticks([],[])\n",
    "plt.title(\"batched\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(out[0][index, :, :, 0], cmap=\"gray\")\n",
    "plt.yticks([],[])\n",
    "plt.xticks([],[])\n",
    "plt.title(\"batched\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
